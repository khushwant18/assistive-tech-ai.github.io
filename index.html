<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Accessible Voice Assistant for Visually Impaired</title>
<style>
* {
  margin: 0;
  padding: 0;
  box-sizing: border-box;
}

body {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Arial, sans-serif;
  background: white;
  color: black;
  padding: 24px;
  line-height: 1.6;
}

.container {
  max-width: 1200px;
  margin: 0 auto;
}

.skip-link {
  position: absolute;
  top: -100px;
  left: 0;
  background: black;
  color: white;
  padding: 16px 24px;
  text-decoration: none;
  font-size: 18px;
  font-weight: bold;
  border: 4px solid #fbbf24;
  z-index: 100;
}

.skip-link:focus {
  top: 16px;
  left: 16px;
}

header {
  margin-bottom: 40px;
  padding-bottom: 24px;
  border-bottom: 4px solid black;
}

h1 {
  font-size: 48px;
  font-weight: bold;
  margin-bottom: 12px;
}

.subtitle {
  font-size: 24px;
  color: #374151;
}

.section {
  background: #f3f4f6;
  padding: 32px;
  border-radius: 8px;
  margin-bottom: 32px;
  border: 4px solid #1f2937;
}

.section-dark {
  background: black;
  color: white;
  border: 4px solid black;
}

.section-title {
  font-size: 32px;
  font-weight: bold;
  margin-bottom: 24px;
  display: flex;
  align-items: center;
  gap: 16px;
}

#status {
  font-size: 24px;
  line-height: 1.5;
}

.voice-button {
  width: 100%;
  padding: 32px;
  font-size: 24px;
  font-weight: bold;
  border-radius: 8px;
  border: 4px solid;
  cursor: pointer;
  display: flex;
  align-items: center;
  justify-content: center;
  gap: 16px;
  transition: all 0.2s;
}

.voice-button:not(.listening):not(:disabled) {
  background: #f97316;
  color: black;
  border-color: #c2410c;
}

.voice-button:not(.listening):not(:disabled):hover {
  background: #ea580c;
}

.voice-button.listening {
  background: white;
  color: black;
  border-color: black;
}

.voice-button:disabled {
  background: #9ca3af;
  color: #4b5563;
  border-color: #6b7280;
  cursor: not-allowed;
}

.voice-button:focus {
  outline: none;
  box-shadow: 0 0 0 8px #fbbf24;
}

.button-hint {
  text-align: center;
  font-size: 20px;
  color: #374151;
  margin-top: 16px;
  font-weight: 600;
}

.input-divider {
  display: flex;
  align-items: center;
  gap: 16px;
  margin: 32px 0;
}

.input-divider-line {
  flex: 1;
  height: 4px;
  background: #1f2937;
}

.input-divider-text {
  font-size: 24px;
  font-weight: bold;
  color: #374151;
}

.text-input-container {
  display: flex;
  gap: 16px;
  margin-top: 24px;
}

.text-input {
  flex: 1;
  padding: 20px;
  font-size: 24px;
  border: 4px solid #1f2937;
  border-radius: 8px;
  background: white;
  color: black;
}

.text-input:focus {
  outline: none;
  box-shadow: 0 0 0 8px #fbbf24;
}

.text-submit-button {
  padding: 20px 40px;
  font-size: 24px;
  font-weight: bold;
  background: #10b981;
  color: white;
  border: 4px solid #059669;
  border-radius: 8px;
  cursor: pointer;
  transition: all 0.2s;
}

.text-submit-button:hover:not(:disabled) {
  background: #059669;
}

.text-submit-button:disabled {
  background: #9ca3af;
  color: #4b5563;
  border-color: #6b7280;
  cursor: not-allowed;
}

.text-submit-button:focus {
  outline: none;
  box-shadow: 0 0 0 8px #fbbf24;
}

.conversation-box {
  background: white;
  padding: 24px;
  border-radius: 8px;
  border: 4px solid #1f2937;
  margin-bottom: 24px;
}

.conversation-header {
  display: flex;
  justify-content: space-between;
  align-items: flex-start;
  margin-bottom: 12px;
}

.conversation-label {
  font-size: 24px;
  font-weight: bold;
  color: #111827;
}

.conversation-text {
  font-size: 24px;
  line-height: 1.6;
  color: black;
}

.repeat-button {
  padding: 12px 24px;
  font-size: 20px;
  font-weight: bold;
  background: #f97316;
  color: black;
  border: 4px solid #c2410c;
  border-radius: 8px;
  cursor: pointer;
  display: flex;
  align-items: center;
  gap: 12px;
  transition: all 0.2s;
}

.repeat-button:hover {
  background: #ea580c;
}

.repeat-button:focus {
  outline: none;
  box-shadow: 0 0 0 8px #fbbf24;
}

.slider-container {
  margin-top: 16px;
}

.slider-label {
  display: block;
  font-size: 24px;
  font-weight: 600;
  color: #111827;
  margin-bottom: 16px;
}

.slider {
  width: 100%;
  height: 16px;
  background: #d1d5db;
  border-radius: 8px;
  outline: none;
  cursor: pointer;
  -webkit-appearance: none;
}

.slider::-webkit-slider-thumb {
  -webkit-appearance: none;
  appearance: none;
  width: 32px;
  height: 32px;
  background: #f97316;
  border: 4px solid #c2410c;
  border-radius: 50%;
  cursor: pointer;
}

.slider::-moz-range-thumb {
  width: 32px;
  height: 32px;
  background: #f97316;
  border: 4px solid #c2410c;
  border-radius: 50%;
  cursor: pointer;
}

.slider:focus {
  box-shadow: 0 0 0 8px #fbbf24;
}

.slider-hint {
  font-size: 20px;
  color: #374151;
  margin-top: 16px;
}

.shortcuts-list {
  list-style: none;
  font-size: 20px;
  line-height: 2;
}

.shortcuts-list li {
  margin-bottom: 16px;
}

.shortcuts-list strong {
  font-size: 24px;
}

.icon {
  width: 40px;
  height: 40px;
  display: inline-block;
  vertical-align: middle;
}

.sr-only {
  position: absolute;
  width: 1px;
  height: 1px;
  padding: 0;
  margin: -1px;
  overflow: hidden;
  clip: rect(0, 0, 0, 0);
  white-space: nowrap;
  border-width: 0;
}

.hidden {
  display: none;
}

audio {
  width: 100%;
  margin-top: 16px;
  height: 60px;
}

.source-info {
  font-size: 18px;
  color: #6b7280;
  margin-top: 12px;
  font-style: italic;
}
.console-section {
  background: #1a1a1a;
  color: #00ff00;
  font-family: 'Courier New', monospace;
  padding: 16px;
  border-radius: 8px;
  margin-top: 32px;
  border: 4px solid #333;
  max-height: 400px;
  overflow-y: auto;
}

.console-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 16px;
  padding-bottom: 12px;
  border-bottom: 2px solid #00ff00;
}

.console-title {
  font-size: 20px;
  font-weight: bold;
  color: #00ff00;
}

.console-clear-btn {
  padding: 8px 16px;
  font-size: 14px;
  font-weight: bold;
  background: #333;
  color: #00ff00;
  border: 2px solid #00ff00;
  border-radius: 4px;
  cursor: pointer;
}

.console-clear-btn:hover {
  background: #00ff00;
  color: #1a1a1a;
}

.console-output {
  font-size: 14px;
  line-height: 1.8;
  white-space: pre-wrap;
  word-break: break-word;
}

.console-log {
  color: #00ff00;
  margin: 4px 0;
}

.console-error {
  color: #ff4444;
  margin: 4px 0;
}

.console-warn {
  color: #ffaa00;
  margin: 4px 0;
}

.console-info {
  color: #00aaff;
  margin: 4px 0;
}

.console-timestamp {
  color: #888;
  font-size: 12px;
  margin-right: 8px;
}


</style>
</head>
<body>
<div class="container">
  <a href="#main-content" class="skip-link">Skip to main content</a>

  <header>
    <h1>Accessible Voice Assistant</h1>
    <p class="subtitle">Voice-first AI assistant for visually impaired users</p>
  </header>

  <main id="main-content">
    <div class="section section-dark" role="region" aria-label="System Status">
      <div class="section-title">
        <svg class="icon" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-hidden="true">
          <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M15.536 8.464a5 5 0 010 7.072m2.828-9.9a9 9 0 010 12.728M5.586 15H4a1 1 0 01-1-1v-4a1 1 0 011-1h1.586l4.707-4.707C10.923 3.663 12 4.109 12 5v14c0 .891-1.077 1.337-1.707.707L5.586 15z"/>
        </svg>
        <span>Status</span>
      </div>
      <p id="status">Loading models...</p>
    </div>

    <div class="section">
      <h2 class="section-title">Voice Input</h2>
      <button id="voiceButton" class="voice-button" disabled aria-label="Start listening">
        <svg class="icon" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-hidden="true">
          <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M19 11a7 7 0 01-7 7m0 0a7 7 0 01-7-7m7 7v4m0 0H8m4 0h4m-4-8a3 3 0 01-3-3V5a3 3 0 116 0v6a3 3 0 01-3 3z"/>
        </svg>
        <span id="buttonText">PRESS SPACE OR CLICK TO SPEAK</span>
      </button>
      <p class="button-hint">Keyboard shortcut: Press Space bar</p>

      <div class="input-divider">
        <div class="input-divider-line"></div>
        <span class="input-divider-text">OR</span>
        <div class="input-divider-line"></div>
      </div>

      <h2 class="section-title">Text Input</h2>
      <div class="text-input-container">
        <input 
          type="text" 
          id="textInput" 
          class="text-input" 
          placeholder="Type your question here..."
          aria-label="Type your question"
          disabled
        >
        <button id="textSubmit" class="text-submit-button" aria-label="Submit text question" disabled>
          <svg class="icon" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-hidden="true">
            <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M14 5l7 7m0 0l-7 7m7-7H3"/>
          </svg>
          SEND
        </button>
      </div>
      <p class="button-hint">Or press Enter to submit your question</p>
    </div>

    <div id="conversationSection" class="section hidden">
      <h2 class="section-title">Current Conversation</h2>
      
      <div id="transcriptionBox" class="conversation-box hidden">
        <p class="conversation-label">You said:</p>
        <p id="transcriptionText" class="conversation-text"></p>
      </div>
      
      <div id="responseBox" class="conversation-box hidden">
        <div class="conversation-header">
          <p class="conversation-label">Assistant response:</p>
          <button id="repeatButton" class="repeat-button" aria-label="Repeat last response. Press Control R">
            <svg class="icon" fill="none" stroke="currentColor" viewBox="0 0 24 24" aria-hidden="true">
              <path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 4v5h.582m15.356 2A8.001 8.001 0 004.582 9m0 0H9m11 11v-5h-.581m0 0a8.003 8.003 0 01-15.357-2m15.357 2H15"/>
            </svg>
            <span>REPEAT</span>
          </button>
        </div>
        <p id="responseText" class="conversation-text"></p>
        <p id="sourceInfo" class="source-info"></p>
      </div>
      
      <audio id="audio" controls style="display:none"></audio>
    </div>

    <div class="section">
      <h2 class="section-title">Settings</h2>
      <div class="slider-container">
        <label for="speechRate" class="slider-label">Speech Rate: <span id="rateValue">1.0</span>x</label>
        <input 
          type="range" 
          id="speechRate" 
          class="slider" 
          min="0.5" 
          max="2.0" 
          step="0.1" 
          value="1.0"
          aria-label="Adjust speech rate from 0.5 to 2.0 times normal speed"
        >
        <p class="slider-hint">Adjust how fast the assistant speaks (0.5x slow to 2.0x fast)</p>
      </div>
    </div>

    <div class="section section-dark">
      <h2 class="section-title">Keyboard Shortcuts</h2>
      <ul class="shortcuts-list">
        <li><strong>Space:</strong> Start or stop voice input</li>
        <li><strong>Enter:</strong> Submit text question</li>
        <li><strong>Control + R:</strong> Repeat last response</li>
        <li><strong>Control + H:</strong> Hear help information</li>
        <li><strong>Tab:</strong> Navigate between controls</li>
      </ul>
    </div>

    <div class="console-section">
      <div class="console-header">
        <div class="console-title">Console Output</div>
        <button id="consoleClearBtn" class="console-clear-btn">Clear Console</button>
      </div>
      <div id="consoleOutput" class="console-output"></div>
    </div>
  </main>
</div>

<div id="announcer" role="status" aria-live="polite" aria-atomic="true" class="sr-only"></div>

<script>
window.Module = window.Module || {};
Module.locateFile = function(path) {
  if (path.endsWith('espeakng.worker.data')) {
    return 'https://raw.githubusercontent.com/khushwant18/piper-test/refs/heads/main/espeakng.worker.data';
  }
  return path;
};
</script>

<script type="module">
// import { pipeline, env } from 'https://cdn.jsdelivr.net/npm/@huggingface/transformers@3.7.6/dist/transformers.min.js';
import { pipeline, env, TextStreamer } from 'https://cdn.jsdelivr.net/npm/@huggingface/transformers@3/dist/transformers.min.js';

env.allowLocalModels = false;
// Console override setup
const consoleOutput = document.getElementById('consoleOutput');
const consoleClearBtn = document.getElementById('consoleClearBtn');

function getTimestamp() {
  const now = new Date();
  return now.toTimeString().split(' ')[0];
}

function addConsoleMessage(message, type = 'log') {
  const line = document.createElement('div');
  line.className = `console-${type}`;
  
  const timestamp = document.createElement('span');
  timestamp.className = 'console-timestamp';
  timestamp.textContent = `[${getTimestamp()}]`;
  
  const text = document.createElement('span');
  text.textContent = ` ${message}`;
  
  line.appendChild(timestamp);
  line.appendChild(text);
  consoleOutput.appendChild(line);
  
  // Auto-scroll to bottom
  consoleOutput.scrollTop = consoleOutput.scrollHeight;
}

// Override console methods
const originalConsole = {
  log: console.log,
  error: console.error,
  warn: console.warn,
  info: console.info
};

console.log = function(...args) {
  originalConsole.log.apply(console, args);
  addConsoleMessage(args.join(' '), 'log');
};

console.error = function(...args) {
  originalConsole.error.apply(console, args);
  addConsoleMessage(args.join(' '), 'error');
};

console.warn = function(...args) {
  originalConsole.warn.apply(console, args);
  addConsoleMessage(args.join(' '), 'warn');
};

console.info = function(...args) {
  originalConsole.info.apply(console, args);
  addConsoleMessage(args.join(' '), 'info');
};

consoleClearBtn.addEventListener('click', () => {
  consoleOutput.innerHTML = '';
  console.log('Console cleared');
});

// Initial message
console.log('Console initialized');




const voiceButton = document.getElementById('voiceButton');
const buttonText = document.getElementById('buttonText');
const status = document.getElementById('status');
const announcer = document.getElementById('announcer');
const transcriptionBox = document.getElementById('transcriptionBox');
const transcriptionText = document.getElementById('transcriptionText');
const responseBox = document.getElementById('responseBox');
const responseText = document.getElementById('responseText');
const sourceInfo = document.getElementById('sourceInfo');
const conversationSection = document.getElementById('conversationSection');
const repeatButton = document.getElementById('repeatButton');
const audioEl = document.getElementById('audio');
const speechRateSlider = document.getElementById('speechRate');
const rateValue = document.getElementById('rateValue');
const textInput = document.getElementById('textInput');
const textSubmit = document.getElementById('textSubmit');

let sttPipeline = null;
let llmPipeline = null;
let bm25Index = null;
let bm25Documents = null;
let piperTTS = null;
let mediaRecorder = null;
let audioChunks = [];
let isRecording = false;
let audioContext = new AudioContext();
let isListening = false;
let isProcessing = false;
let currentResponse = '';

let vadStream = null;
let vadAudioContext = null;
let vadAnalyser = null;
let vadSource = null;
let vadCheckInterval = null;
const VAD_THRESHOLD = 0.02;
const VAD_SILENCE_DURATION = 1500;
let lastSoundTime = Date.now();

let voiceFeedbackQueue = [];
let isPlayingFeedback = false;
let processedLength = 0;
let audioQueue = [];
let isPlayingQueue = false;

async function waitForFeedback() {
  return new Promise(resolve => {
    const checkFeedback = setInterval(() => {
      if (!isPlayingFeedback && voiceFeedbackQueue.length === 0) {
        clearInterval(checkFeedback);
        resolve();
      }
    }, 100);
  });
}

async function announceStatus(message, speak = false) {
  status.textContent = message;
  announcer.textContent = message;
  console.log('ðŸ“¢', message);
  
  if (speak && piperTTS) {
    await speakFeedback(message);
  }
}

async function speakFeedback(message) {
  voiceFeedbackQueue.push(message);
  if (!isPlayingFeedback) {
    await playNextFeedback();
  }
}

async function playNextFeedback() {
  if (voiceFeedbackQueue.length === 0) {
    isPlayingFeedback = false;
    return;
  }
  
  isPlayingFeedback = true;
  const message = voiceFeedbackQueue.shift();
  
  try {
    console.log('ðŸ”Š Generating speech for:', message);
    console.log('piperTTS object:', piperTTS);
    console.log('piperTTS.textToWavAudio:', piperTTS?.textToWavAudio);
    
    // Check if piperTTS is properly initialized
    if (!piperTTS || typeof piperTTS.textToWavAudio !== 'function') {
      console.error('PiperTTS not properly initialized');
      playNextFeedback();
      return;
    }
    
    const wavBlob = await piperTTS.textToWavAudio(message, 0);
    
    // Validate the blob
    console.log('Blob received:', wavBlob, 'Type:', typeof wavBlob, 'instanceof Blob:', wavBlob instanceof Blob);
    
    if (!wavBlob || !(wavBlob instanceof Blob)) {
      console.error('Invalid blob received from TTS:', wavBlob);
      playNextFeedback();
      return;
    }
    
    const audioURL = URL.createObjectURL(wavBlob);
    const feedbackAudio = new Audio(audioURL);
    feedbackAudio.playbackRate = parseFloat(speechRateSlider.value);
    
    feedbackAudio.onended = () => {
      URL.revokeObjectURL(audioURL); 
      playNextFeedback();
    };

    feedbackAudio.onerror = (e) => {
      console.error('Audio playback error:', e);
      URL.revokeObjectURL(audioURL);
      playNextFeedback();
    };
    
    await feedbackAudio.play();
  } catch (err) {
    console.error('Feedback speech error:', err);
    console.error('Full error details:', err.stack);
    playNextFeedback();
  }
}

async function loadOrt() {
  return new Promise((resolve) => {
    if (window.ort) {
      resolve();
      return;
    }
    const s = document.createElement('script');
    s.src = 'https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js';
    s.onload = resolve;
    document.head.appendChild(s);
  });
}

async function loadBM25Index() {
  try {
    announceStatus('Loading book index...');
    const response = await fetch('bm25_index.json');
    const data = await response.json();
    bm25Index = data.index;
    bm25Documents = data.documents;
    console.log(`ðŸ“š Loaded ${bm25Documents.length} paragraphs from index`);
  } catch (err) {
    console.error('Error loading BM25 index:', err);
    throw new Error('Failed to load book index');
  }
}

function prepareText(text) {
  return text.toLowerCase()
    .replace(/[^\w\s]/g, ' ')
    .split(/\s+/)
    .filter(w => w.length > 2);
}

function bm25Search(query, topK = 3) {
  const queryTokens = prepareText(query);
  const scores = [];
  
  for (let i = 0; i < bm25Documents.length; i++) {
    const doc = bm25Documents[i];
    const docTokens = prepareText(doc.text);
    
    let score = 0;
    for (const token of queryTokens) {
      if (docTokens.includes(token)) {
        score += 1;
      }
    }
    
    if (score > 0) {
      scores.push({ doc, score, index: i });
    }
  }
  
  scores.sort((a, b) => b.score - a.score);
  return scores.slice(0, topK);
}

async function initModels() {
  try {
    announceStatus('Loading speech recognition system...');
    
    sttPipeline = await pipeline('automatic-speech-recognition', 'onnx-community/whisper-tiny', {
      dtype: 'q4',
      device: 'wasm'
    });

    announceStatus('Loading language model...');
    
    llmPipeline = await pipeline('text-generation', 'onnx-community/LFM2-350M-ONNX', {
      dtype: 'q4f16',
      device: 'wasm'
    });

    announceStatus('Loading book index...');
    await loadBM25Index();

    announceStatus('Loading text to speech system...');
    
    await loadOrt();
    piperTTS = await import('https://cdn.jsdelivr.net/gh/khushwant18/piper-test@main/resources/piper.js');
    
    const MODEL_URL = 'https://huggingface.co/rhasspy/piper-voices/resolve/main/en/en_US/hfc_female/medium/en_US-hfc_female-medium.onnx';
    const CONFIG_URL = 'https://huggingface.co/rhasspy/piper-voices/resolve/main/en/en_US/hfc_female/medium/en_US-hfc_female-medium.onnx.json';
    
    await piperTTS.setVoice(MODEL_URL, CONFIG_URL);

    announceStatus('System ready. Press Space to start voice input or type your question.', false);
    voiceButton.disabled = false;
    textInput.disabled = false;
    textSubmit.disabled = false;
    
  } catch (err) {
    console.error('Model loading error:', err);
    announceStatus('Error loading models. Please refresh the page.');
  }
}
  
async function setupVAD() {
  try {
    announceStatus('Requesting microphone access...', true);
    
    vadStream = await navigator.mediaDevices.getUserMedia({
      audio: {
        channelCount: 1,
        sampleRate: 16000,
        echoCancellation: true,
        noiseSuppression: true,
        autoGainControl: true
      }
    });

    vadAudioContext = new AudioContext();
    vadAnalyser = vadAudioContext.createAnalyser();
    vadAnalyser.fftSize = 2048;
    vadSource = vadAudioContext.createMediaStreamSource(vadStream);
    vadSource.connect(vadAnalyser);

    const bufferLength = vadAnalyser.frequencyBinCount;
    const dataArray = new Uint8Array(bufferLength);
    let isCurrentlyRecording = false;

    vadCheckInterval = setInterval(() => {
      if (isProcessing) return;
      
      vadAnalyser.getByteTimeDomainData(dataArray);

      let sum = 0;
      for (let i = 0; i < bufferLength; i++) {
        const normalized = (dataArray[i] - 128) / 128;
        sum += normalized * normalized;
      }
      const rms = Math.sqrt(sum / bufferLength);

      if (rms > VAD_THRESHOLD) {
        lastSoundTime = Date.now();
        if (!isCurrentlyRecording) {
          startRecording();
          isCurrentlyRecording = true;
        }
      } else if (isCurrentlyRecording && Date.now() - lastSoundTime > VAD_SILENCE_DURATION) {
        stopRecording();
        isCurrentlyRecording = false;
      }
    }, 100);

    isListening = true;
    voiceButton.classList.add('listening');
    buttonText.textContent = 'STOP LISTENING';
    voiceButton.setAttribute('aria-label', 'Stop listening. Press Space key');
    announceStatus('Listening. Speak now.', true);
    
    return true;
  } catch (err) {
    console.error('Microphone error:', err);
    announceStatus('Could not access microphone. Please check permissions and try again.', true);
    return false;
  }
}

function stopVAD() {
  if (vadCheckInterval) {
    clearInterval(vadCheckInterval);
    vadCheckInterval = null;
  }
  if (vadSource) {
    vadSource.disconnect();
    vadSource = null;
  }
  if (vadAudioContext) {
    vadAudioContext.close();
    vadAudioContext = null;
  }
  if (vadStream) {
    vadStream.getTracks().forEach(track => track.stop());
    vadStream = null;
  }
  if (isRecording) {
    stopRecording();
  }
  
  if (audioEl) {
    if (audioEl.src) {
      URL.revokeObjectURL(audioEl.src);  // â† ADD THIS: Clean up current audio URL
    }
    audioEl.pause();
    audioEl.currentTime = 0;
    audioEl.src = ''; 
  }
  
  audioQueue = []; 
  voiceFeedbackQueue = [];
  isPlayingFeedback = false;
  
  isListening = false;
  voiceButton.classList.remove('listening');
  buttonText.textContent = 'PRESS SPACE OR CLICK TO SPEAK';
  voiceButton.setAttribute('aria-label', 'Start listening. Press Space key');
  announceStatus('Voice system stopped.');
}

function startRecording() {
  try {
    mediaRecorder = new MediaRecorder(vadStream);
    audioChunks = [];

    mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
    mediaRecorder.onstop = async () => {
      const audioBlob = new Blob(audioChunks, { type: mediaRecorder.mimeType });
      audioChunks = []; 
      await processAudio(audioBlob);
    };

    mediaRecorder.start(100);
    isRecording = true;
    announceStatus('Recording your voice...');
  } catch (err) {
    console.error('Recording error:', err);
    announceStatus('Error starting recording.', true);
  }
}

function stopRecording() {
  if (mediaRecorder && isRecording) {
    mediaRecorder.stop();
    isRecording = false;
    announceStatus('Processing your speech...', true);
  }
}

async function processAudio(audioBlob) {
  if (!sttPipeline || isProcessing) return;

  try {
    isProcessing = true;
    voiceButton.disabled = true;
    textInput.disabled = true;
    textSubmit.disabled = true;
    announceStatus('Converting speech to text...', true);
    await waitForFeedback();

    const arrayBuffer = await audioBlob.arrayBuffer();
    const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
    const audioData = audioBuffer.getChannelData(0);
    
    let maxAmplitude = 0;
    for (let i = 0; i < audioData.length; i++) {
      maxAmplitude = Math.max(maxAmplitude, Math.abs(audioData[i]));
    }

    if (maxAmplitude < 0.01) {
      announceStatus('Audio too quiet. Please speak louder.', true);
      await waitForFeedback();
      isProcessing = false;
      voiceButton.disabled = false;
      textInput.disabled = false;
      textSubmit.disabled = false;
      return;
    }

    const targetSampleRate = 16000;
    const sourceSampleRate = audioBuffer.sampleRate;
    let resampledData = audioData;

    if (sourceSampleRate !== targetSampleRate) {
      const ratio = sourceSampleRate / targetSampleRate;
      const newLength = Math.round(audioData.length / ratio);
      resampledData = new Float32Array(newLength);

      for (let i = 0; i < newLength; i++) {
        const srcIndex = i * ratio;
        const srcIndexFloor = Math.floor(srcIndex);
        const srcIndexCeil = Math.min(srcIndexFloor + 1, audioData.length - 1);
        const t = srcIndex - srcIndexFloor;
        resampledData[i] = audioData[srcIndexFloor] * (1 - t) + audioData[srcIndexCeil] * t;
      }
    }

    const result = await sttPipeline(resampledData);
    const text = result.text.trim();

    if (!text) {
      announceStatus('No speech detected. Please try again.', true);
      await waitForFeedback();
      isProcessing = false;
      voiceButton.disabled = false;
      textInput.disabled = false;
      textSubmit.disabled = false;
      return;
    }

    transcriptionText.textContent = text;
    transcriptionBox.classList.remove('hidden');
    conversationSection.classList.remove('hidden');
    
    announceStatus(`You said: ${text}`, true);
    await waitForFeedback();
    
    await processText(text);

  } catch (error) {
    console.error('Audio processing error:', error);
    announceStatus('Error processing audio. Please try again.', true);
    await waitForFeedback();
    isProcessing = false;
    voiceButton.disabled = false;
    textInput.disabled = false;
    textSubmit.disabled = false;
  }
}

async function processText(text) {
  try {
    announceStatus('Searching the book for relevant information...', true);
    await waitForFeedback();
    
    const searchResults = bm25Search(text, 3);
    
    if (searchResults.length === 0) {
      const noResultMessage = 'I could not find relevant information in the book for your question.';
      currentResponse = noResultMessage;
      responseText.textContent = noResultMessage;
      sourceInfo.textContent = '';
      responseBox.classList.remove('hidden');
      
      // announceStatus('Here is your answer.', true);
      await waitForFeedback();
      
      const wavBlob = await piperTTS.textToWavAudio(noResultMessage, 0);
      const audioURL = URL.createObjectURL(wavBlob);  // â† ADD THIS LINE HERE
      audioEl.src = audioURL;


      audioEl.src = URL.createObjectURL(wavBlob);
      audioEl.style.display = 'block';
      audioEl.playbackRate = parseFloat(speechRateSlider.value);
      
      audioEl.onended = () => {
        URL.revokeObjectURL(audioURL);  
        announceStatus('Response complete. Press Space for voice input or type your question.');
        isProcessing = false;
        voiceButton.disabled = false;
        textInput.disabled = false;
        textSubmit.disabled = false;
      };

      audioEl.onerror = () => {  // â† ADD THIS: Handle errors
        URL.revokeObjectURL(audioURL);
      };
      
      await audioEl.play();
      return;
    }
    
    console.log(`ðŸ“š Found ${searchResults.length} relevant paragraphs`);
    
    const context = searchResults.map(r => 
                                        `From ${r.doc.chapter}: ${r.doc.text}`
                                      ).join('\n\n');
    const topResult = searchResults[0].doc;
    
    processedLength = 0;
    audioQueue = [];
    isPlayingQueue = false;
    currentResponse = '';
    
    responseBox.classList.remove('hidden');
    conversationSection.classList.remove('hidden');
    audioEl.style.display = 'block';
    
    announceStatus('Generating answer from the book...', true);
    await waitForFeedback();
    console.log(`context given ${context}`)

    const prompt = `Based on the following information from the book, answer the question concisely in 2-3 sentences and mention chapter name in the end from which answer was formed.

Context from book: ${context}

Question: ${text}

Answer naturally and mention the chapter if relevant.`;

    const messages = [
      { 
        role: "system", 
        content: "You are a helpful assistant for visually impaired users. NEVER suggest looking at anything or visual verification. NEVER use phrases like 'look at', 'see', 'view', or 'watch'. Always provide audio-friendly, concise answers in 2-3 clear sentences based on the book context provided. Speak naturally and avoid technical jargon." 
      },
      { role: "user", content: prompt }
    ];

    const streamer = new TextStreamer(llmPipeline.tokenizer, {
      skip_prompt: true,
      callback_function: (text) => {
        currentResponse += text;
        responseText.textContent = currentResponse;
        processStreamedText(currentResponse);
      }
    });

    await llmPipeline(messages, { 
      max_new_tokens: 100,
      streamer: streamer
    });
    
    if (processedLength < currentResponse.length) {
      const remaining = currentResponse.slice(processedLength).trim();
      if (remaining.length > 0) {
        await queueSentenceForTTS(remaining);
      }
    }
    
    sourceInfo.textContent = `Source: ${topResult.chapter}, Page ${topResult.page}`;
    console.log(`ðŸ¤– AI Response: "${currentResponse}"`);
    
    // announceStatus('Here is your answer.', true);
    await waitForFeedback();
    
    const waitForAudioComplete = setInterval(() => {
      if (!isPlayingQueue && audioQueue.length === 0) {
        clearInterval(waitForAudioComplete);
        announceStatus('Response complete. Press Space for voice input or type your question.');
        isProcessing = false;
        voiceButton.disabled = false;
        textInput.disabled = false;
        textSubmit.disabled = false;
      }
    }, 100);

  } catch (err) {
    console.error('âŒ Error:', err);
    const errorMessage = 'I encountered an error. Please try again.';
    announceStatus(errorMessage, true);
    await waitForFeedback();
    isProcessing = false;
    voiceButton.disabled = false;
    textInput.disabled = false;
    textSubmit.disabled = false;
  }
}
function repeatLastResponse() {
  if (currentResponse && piperTTS) {
    announceStatus('Repeating last response...', true);
    
    setTimeout(async () => {
      const wavBlob = await piperTTS.textToWavAudio(currentResponse, 0);
      const audioURL = URL.createObjectURL(wavBlob);  // â† ADD THIS LINE HERE
      audioEl.src = audioURL;
      audioEl.playbackRate = parseFloat(speechRateSlider.value);

      const oldOnended = audioEl.onended;
      audioEl.onended = () => {
        URL.revokeObjectURL(audioURL);  // â† ADD THIS: Clean up URL
        if (oldOnended) oldOnended();  // Restore original handler
      };

      audioEl.play();
    }, 1000);
  } else {
    announceStatus('No response to repeat.', true);
  }
}

async function announceHelp() {
  const helpMessage = "Voice Assistant Help. Press Space to start or stop recording. Press Enter to submit text questions. Press Control R to repeat the last response. Press Control H for help.";
  announceStatus(helpMessage, true);
}

async function handleTextSubmit() {
  const text = textInput.value.trim();
  
  if (!text) {
    announceStatus('Please enter a question.', true);
    await waitForFeedback();
    return;
  }
  
  if (isProcessing) {
    announceStatus('Please wait for the current question to be processed.', true);
    await waitForFeedback();
    return;
  }
  
  transcriptionText.textContent = text;
  transcriptionBox.classList.remove('hidden');
  conversationSection.classList.remove('hidden');
  
  announceStatus(`You asked: ${text}`, true);
  await waitForFeedback();
  
  textInput.value = '';
  
  await processText(text);
}

function processStreamedText(fullText) {
  // Extract new text that hasn't been processed
  const newText = fullText.slice(processedLength);
  
  // Look for complete sentences (ending with . ! ?)
  const sentenceRegex = /[^.!?]+[.!?]+/g;
  const sentences = newText.match(sentenceRegex);
  
  if (sentences) {
    sentences.forEach(sentence => {
      const trimmed = sentence.trim();
      if (trimmed.length > 0) {
        queueSentenceForTTS(trimmed);
        processedLength += sentence.length;
      }
    });
  }
}

async function queueSentenceForTTS(sentence) {
  try {
    const wavBlob = await piperTTS.textToWavAudio(sentence, 0);
    audioQueue.push({
      blob: wavBlob,
      text: sentence
    });
    
    if (!isPlayingQueue) {
      playAudioQueue();
    }
  } catch (err) {
    console.error('TTS error for sentence:', err);
  }
}

async function playAudioQueue() {
  if (audioQueue.length === 0) {
    isPlayingQueue = false;
    return;
  }
  
  isPlayingQueue = true;
  const audioItem = audioQueue.shift();
  
  const audioURL = URL.createObjectURL(audioItem.blob);  // â† ADD THIS LINE HERE
  audioEl.src = audioURL;
  audioEl.playbackRate = parseFloat(speechRateSlider.value);
  
  audioEl.onended = () => {
    URL.revokeObjectURL(audioURL); 
    playAudioQueue();
  };

   audioEl.onerror = () => {  // â† ADD THIS: Handle errors
    URL.revokeObjectURL(audioURL);
    playAudioQueue();
  };
  
  await audioEl.play();
}

voiceButton.addEventListener('click', async () => {
  if (isProcessing) {
    stopVAD();
    isProcessing = false;
    voiceButton.disabled = false;
    textInput.disabled = false;
    textSubmit.disabled = false;
    announceStatus('Processing stopped.', true);
  } else if (isListening) {
    stopVAD();
  } else {
    await setupVAD();
  }
});

repeatButton.addEventListener('click', repeatLastResponse);

textSubmit.addEventListener('click', handleTextSubmit);

textInput.addEventListener('keydown', (e) => {
  if (e.key === 'Enter') {
    e.preventDefault();
    handleTextSubmit();
  }
});

speechRateSlider.addEventListener('input', (e) => {
  const rate = parseFloat(e.target.value);
  rateValue.textContent = rate.toFixed(1);
  if (audioEl) {
    audioEl.playbackRate = rate;
  }
});

document.addEventListener('keydown', (e) => {
  if (e.code === 'Space' && e.target.tagName !== 'INPUT') {
    e.preventDefault();
    voiceButton.click();
  }
  else if (e.code === 'KeyR' && e.ctrlKey) {
    e.preventDefault();
    repeatLastResponse();
  }
  else if (e.code === 'KeyH' && e.ctrlKey) {
    e.preventDefault();
    announceHelp();
  }
});

initModels();
</script>
</body>
</html>
